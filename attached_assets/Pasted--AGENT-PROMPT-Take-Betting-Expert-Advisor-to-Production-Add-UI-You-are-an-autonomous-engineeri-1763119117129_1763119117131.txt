
AGENT PROMPT — “Take Betting Expert Advisor to Production + Add UI”
You are an autonomous engineering agent. Your job: turn the repository at /home/evans/Projects/Betting Expert Advisor into a production-ready service and add a modern web UI. Work in small commits grouped by tasks, run linters and tests after each task group, and produce a final report listing changes, branch names and commits, CI config, Docker images built, and how to deploy. Use safe defaults; do not alter domain logic beyond making it configurable, better-tested, or fixing clear bugs that block production readiness.
Make no assumptions not in this repo (ask nothing). If a required secret or external service is missing, create a clear placeholder and document how the user must populate it. Do not push to remote; create local git branches and commit. For every change, include a one-line commit message prefixed with prod: and the task number (e.g. prod(1): ...).
Work sequentially through the tasks below. After each numbered Task Group completes, run linters and tests (isort, black, flake8, mypy, pytest). If a test or lint fails, fix the minimal code to make it pass. For any tests you must change, update tests accordingly and explain why. At the end produce the Final Report.

TASK GROUPS (execute in order)
Task Group 0 — Setup & baseline
Create branch prod-ready/phase0/setup.


Ensure virtualenv activation is documented: check .venv/ exists. If not, create python -m venv .venv.


Install dev dependencies from requirements-dev.txt and requirements.txt. If packages are missing in the repo, create requirements-dev.txt with flake8 black isort mypy pytest pytest-cov ruff pybreaker python-dotenv and install.


Run isort . && black . && flake8 && mypy and capture output. If any of these commands fail due to pre-existing errors (type issues or flake8), do not silence them — fix only what you introduced or critical issues that block production tasks. Commit changes as prod(0): setup env & run formatters.


Acceptance criteria:
Environment ready and commands run cleanly or show existing errors clearly captured in report.



Task Group 1 — Completed already: Logger standardization verification
(This was done, but verify consistency)
Create branch prod-ready/phase1/verify-logging from current HEAD.


Scan entire repo for logging.getLogger( and any get_logger definitions; ensure only src/logging_config.get_logger is the canonical function. Exclude src/config.py if circular.


Remove unused logging imports introduced by refactor. Run linters and fix issues.


Commit as prod(1): verify logging standardization.


Acceptance:
flake8 should not show new F401 or logger-related errors introduced by refactor.



Task Group 2 — Unify DB session management
Create branch prod-ready/phase2/unify-db.


Pick a single canonical DB context manager — handle_db_errors() (if it already exists and handles rollback/commit) — and refactor code so all DB access in src/ uses it. If handle_db_errors() is not complete, update it to provide context manager that:


yields a SQLAlchemy session


commits on success


rolls back and re-raises the original exception on error (preserve error type)


does not close session until after commit()/rollback() is complete


Update functions that returned ORM objects tied to closed sessions (like save_bet) to either:


refresh before returning and return plain dataclass/dict or


copy values into a detached dataclass/DTO to avoid DetachedInstanceError.
 Prefer returning dataclass/Dict for boundary functions (i.e., anything used by scripts or adapters).


Add unit tests (or modify existing tests) to assert:


save_bet(...).placed_at is set and accessible without DetachedInstanceError.


idempotency logic still returns existing bet metadata correctly.


Commit as prod(2): unify DB session management & fix detached instances.


Acceptance:
pytest tests/test_db*.py for DB-related tests pass.


No DetachedInstanceError occurs in test runs.



Task Group 3 — Circuit Breaker for external APIs
Create branch prod-ready/phase3/circuit-breaker.


Add pybreaker to requirements and import it.


Implement a circuit breaker wrapper in src/adapters/_circuit.py:


default config: fail_max=5, timeout_duration=60 seconds (configurable by config.py).


Provide decorator @with_circuit_breaker(name) and helper to call it.


Wrap adapter network calls (src/adapters/theodds_api.py, src/adapters/pinnacle_client.py, src/adapters/betfair_exchange.py) such that:


network call goes through the breaker


on CircuitBreakerError:


log a warning


return cached data if available (use src/cache.py), else raise a controlled ExternalServiceUnavailable exception (create this in src/utils.py or src/errors.py)


Add unit tests to simulate repeated adapter failure and ensure:


after fail_max attempts, breaker opens and next call uses fallback or raises ExternalServiceUnavailable.


Commit as prod(3): add circuit breaker to adapters.


Acceptance:
Adapter tests asserting retry/circuit behavior pass.


No regressions in other tests.



Task Group 4 — Global exception handling for API (monitoring layer)
Create branch prod-ready/phase4/api-exceptions.


If there is a FastAPI app at src/monitoring.py or src/main.py, add a global exception handler:


logs full traceback


returns {"error": "internal_server_error"} with HTTP 500 for unhandled exceptions


calls send_alert() for critical severity (if send_alert exists; otherwise create placeholder function that logs and documents how to wire up Slack/Telegram/Sentry)


Add Pydantic models for any public POST endpoints if missing.


Add tests that POST invalid payloads and assert HTTP 422 or 500 as appropriate.


Commit prod(4): add FastAPI global exception handler & validation.


Acceptance:
FastAPI app starts locally (no import cycle) and global handler exists.


Tests for API validation pass.



Task Group 5 — Move constants into config
Branch prod-ready/phase5/config.


Add risk & circuit-breaker config entries to src/config.py with sensible defaults (and environment overrides via Pydantic BaseSettings):


RISK_CONSECUTIVE_LOSSES_WARN=3


RISK_CONSECUTIVE_LOSSES_CUTOFF=5


RISK_DRAWDOWN_WARN=0.15


RISK_DRAWDOWN_CUTOFF=0.20


CIRCUIT_FAIL_MAX=5, CIRCUIT_TIMEOUT_SECONDS=60


EXECUTOR_RATE_LIMIT_PER_MIN=10


Replace hard-coded magic numbers across src/ to reference settings.*.


Add unit tests that confirm the thresholds can be configured via env and behavior changes accordingly.


Commit prod(5): move magic numbers to config and use settings.


Acceptance:
Code uses config values, and changing env variables alters behavior in tests.



Task Group 6 — Consolidate EV calculation
Branch prod-ready/phase6/ev.


Remove duplicate calculate_ev from src/utils.py (if it exists), keep calculate_expected_value() in src/risk.py and make it the canonical function.


Update imports and any unit tests to use the single function.


Ensure decimal precision where required; add unit tests for edge cases (probabilities 0, 1, odds boundary).


Commit prod(6): consolidate expected value calculation.


Acceptance:
No tests fail for EV logic; all references updated.



Task Group 7 — CI, Docker, and deployment pipeline
Branch prod-ready/phase7/ci-docker.


Add Dockerfile (if not present) with multi-stage build:


Use python:3.12-slim as base


Install pkg-config libsystemd-dev if systemd-python previously needed (as earlier note)


Create non-root app user, install deps, run tests in build stage


Final image contains only app and runtime deps


Add docker-compose.yml for local dev: services web (FastAPI), db (Postgres), redis (cache).


Use Postgres (not SQLite) for production-like DB


Add GitHub Actions CI workflow .github/workflows/ci.yml that:


Checks out code


Sets up Python


Installs deps


Runs linters and tests


Builds Docker image and runs pytest in the image


(Optional) stores built image as artifact


Add deployment script examples in deploy/ using docker-compose for staging.


Commit prod(7): add Dockerfile, docker-compose and CI workflow.


Acceptance:
docker build of the app image completes successfully.


CI workflow file present and passes locally in simulation (i.e., commands succeed).



Task Group UI — Create Next.js 14 frontend (separate project)
You will create a frontend app in ui/ at repo root. Prefer Next.js 14 + TypeScript + Tailwind CSS. Keep it as a separate project folder (not embedded static files) to allow independent deployment.
Branch prod-ready/ui/nextjs.


Create ui/ scaffold using Next.js 14 layout (TypeScript).


Tech stack & libraries:


Next.js 14 (app router)


TypeScript


Tailwind CSS


shadcn/ui for components (optional)


lucide-react for icons


recharts or chart.js for charts


use SWR or React Query for data fetching


Pages / routes to implement (minimum MVP):


/ Dashboard — summary: current bankroll, open bets, last 30-day P&L chart, health status


/backtest — run backtest (form to upload CSV / pick model), show results & charts


/live — live tracker page with WebSocket updates of open bets and metrics


/settings — show configuration values (read-only) and toggle for paper/live trading (local only)


/docs — render repo docs (serve Markdown files from ../docs/) — or fetch via API


UI details:


Use Tailwind and maintain a clean card/grid aesthetic


Use charts for PnL and daily stats (recharts)


Use responsive layout


Provide simple mocked auth: a login modal with a mock token stored in localStorage (document how to wire real auth)


Backend API endpoints to ensure for UI (create/confirm these in src/main.py or src/monitoring.py):


GET /api/health


GET /api/stats/summary


GET /api/bets/open


GET /api/backtests/:id + POST /api/backtests to start a backtest


GET /api/models to list saved models


WebSocket /ws/live for streaming events


Implement UI integration with backend using these endpoints (if backend endpoint missing, create minimal endpoints returning mocked data).


Add README in ui/ with dev and build commands, and Dockerfile for the UI.


Commit prod(ui): add Next.js UI MVP.


Acceptance:
cd ui && npm install && npm run dev starts the UI.


UI fetches and displays mocked data if backend endpoints not yet present.


Document how to enable real data (env variables and endpoints).



Reporting & PRs
After finishing each Task Group:
Push commits locally (do not require remote push).


Print a Task Group Report: branch name, commit hash(es), files changed list, linter output (brief), pytest output (brief), and any modified tests.


If a Task Group cannot be completed (missing secrets, external APIs), create placeholders and document exactly how to configure them.


When all groups complete, produce a Final Report that includes:
List of all branches and their head commit hashes


Summary of all changed files


Linting and test status (all tests must pass; if some tests cannot be run due to environment, document why)


Docker image build command and tag


CI workflow status and how to run locally


Frontend dev & build instructions


Deployment checklist (env vars, DB migrations)


One-line rollback plan



Hard constraints & rules
Do not create or publish secrets in the repo. Use .env.template placeholders.


Keep changes minimal and focused; do not refactor unrelated modules.


Always run pytest -q and include output (pass/fail counts).


If any change alters public API semantics, update README.md and docs/ accordingly.


Tests must pass locally for the repo (use Postgres docker container if migrating from SQLite for integration tests; otherwise run unit tests).


If you must skip tests, only skip with clear @pytest.mark.skipif and explain why in the report.


Use clear commit messages: prod(task#): short description.



Final output required (print exactly at the end)
A top-level summary: which tasks succeeded/failed.


For each Task Group: branch name, commit hash, changed files (short list), linter output summary, pytest output, and any manual steps still required from the human.


docker build command used and the final produced image tag (or build output).


How to run UI locally and how to wire it to the backend (env variables).


A single paragraph “Go-live checklist” with exactly the items needed before flipping to production.



Start now and run tasks in order. After each Task Group completes, pause and print the Task Group Report. When everything is done, print the Final Report.
You are authorized to modify code, tests, docs, add files, and create branches. Do NOT perform any remote pushes or publish secrets. Proceed.


